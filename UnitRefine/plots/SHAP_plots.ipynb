{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72744fdd",
   "metadata": {},
   "source": [
    "## SHAP plots in UnitRefine paper\n",
    "\n",
    "\n",
    "This notebook reproduces SHAP-based analyses used in the UnitRefine paper for **SUA vs non-SUA** classification.\n",
    "\n",
    "It demonstrates how to:\n",
    "1. Download an **example metrics dataset** from the Hugging Face Hub.\n",
    "2. Train a simple binary classifier across **10 random seeds** (to quantify stability).\n",
    "3. Compute SHAP values for each seed and plot **mean ± std SHAP importance** across seeds.\n",
    "4. Select the best seed and generate SHAP summary / bar / decision plots.\n",
    "5. Confusion matrix also for the  **best-performing seed** \n",
    "\n",
    "**Expected runtime:** training across 10 seeds can take a few minutes to 30 minuts depending on the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "939a7dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Imports\n",
    "# -----------------------------\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import shap\n",
    "\n",
    "from huggingface_hub import hf_hub_download, list_repo_files\n",
    "from skops.io import load\n",
    "\n",
    "import spikeinterface.curation as sc\n",
    "from spikeinterface.curation.train_manual_curation import train_model\n",
    "\n",
    "from sklearn.metrics import balanced_accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "a386cd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_species_dataset(repo_id: str, species: str):\n",
    "    species = species.lower()\n",
    "    \n",
    "    if species not in repo_id.lower():\n",
    "        raise ValueError(\n",
    "            f\"Repository does not match requested species '{species}'.\"\n",
    "        )\n",
    "\n",
    "    files = list_repo_files(repo_id)\n",
    "    target_file = f\"{species}_dataset.csv\"\n",
    "\n",
    "    if target_file not in files:\n",
    "        raise FileNotFoundError(\n",
    "            f\"{target_file} not found.\\nAvailable files:\\n{files}\"\n",
    "        )\n",
    "\n",
    "    return hf_hub_download(repo_id=repo_id, filename=target_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d4d467",
   "metadata": {},
   "source": [
    "## Define your variables "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71a6321",
   "metadata": {},
   "source": [
    "| hugging_face_model             |species | \n",
    "|------------------------------|----------------------------|\n",
    "|'AnoushkaJain3/UnitRefine-mice-sua-classifier'         | 'mice           | \n",
    "| 'AnoushkaJain3/UnitRefine-mole-rat-sua-classifier'            | 'mole-rat'            | \n",
    "|'AnoushkaJain3/UnitRefine-monkey-sua-classifier'                | 'monkey'          | \n",
    "| 'AnoushkaJain3/UnitRefine-human-sua-classifier'   | 'human'        | \n",
    "\n",
    "\n",
    "Edit the values below if you want to change:\n",
    "- which Hugging Face repo is used \n",
    "- where outputs are written\n",
    "\n",
    "By default, all outputs are saved to a local folder called `outputs/` next to this notebook (cross-platform)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "ed933810",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_base = r'E:\\UnitRefine\\outputs'\n",
    "\n",
    "# Where to write outputs (cross-platform; avoids Windows-only paths)\n",
    "# output_base = Path(\"outputs\")\n",
    "# output_base.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Hugging Face repo containing the example dataset + trained pipeline\n",
    "hugging_face_model = 'AnoushkaJain3/UnitRefine-mice-sua-classifier'\n",
    "species='mice'   # used to auto-locate '<species>_dataset.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91aa7d9e",
   "metadata": {},
   "source": [
    "### Load dataset\n",
    "We automatically download `<species>_dataset.csv` file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "8df2b6ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metrics_path = C:\\Users\\jain\\.cache\\huggingface\\hub\\models--AnoushkaJain3--UnitRefine-mice-sua-classifier\\snapshots\\a3a5ca19c8e7b02d3aca31ed494d3d78a489b7dc\\mice_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "# Download metrics CSV (cached by HF) and show local path\n",
    "metrics_path = download_species_dataset(hugging_face_model, species)\n",
    "print(\"metrics_path =\", metrics_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a5eb7f",
   "metadata": {},
   "source": [
    "### Load feature columns\n",
    "\n",
    "We load a pretrained UnitRefine pipeline to recover the exact feature names (`feature_names_in_`), ensuring the CSV is parsed consistently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "e447720b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quality Metrics being used:  ['num_spikes' 'firing_rate' 'presence_ratio' 'snr' 'isi_violations_ratio'\n",
      " 'isi_violations_count' 'rp_contamination' 'rp_violations'\n",
      " 'sliding_rp_violation' 'amplitude_cutoff' 'amplitude_median'\n",
      " 'amplitude_cv_median' 'amplitude_cv_range' 'sync_spike_2' 'sync_spike_4'\n",
      " 'sync_spike_8' 'firing_range' 'drift_ptp' 'drift_std' 'drift_mad'\n",
      " 'isolation_distance' 'l_ratio' 'd_prime' 'silhouette' 'nn_hit_rate'\n",
      " 'nn_miss_rate' 'peak_to_valley' 'peak_trough_ratio' 'half_width'\n",
      " 'repolarization_slope' 'recovery_slope' 'num_positive_peaks'\n",
      " 'num_negative_peaks' 'velocity_above' 'velocity_below' 'exp_decay'\n",
      " 'spread']\n",
      "\n",
      "Total features : 37\n"
     ]
    }
   ],
   "source": [
    "import spikeinterface.curation as sc\n",
    "\n",
    "model, model_info = sc.load_model(\n",
    "    repo_id = hugging_face_model,\n",
    "    trusted = ['numpy.dtype']\n",
    ")\n",
    "\n",
    "feature_columns = model.feature_names_in_\n",
    "print(\"Quality Metrics being used: \", feature_columns)\n",
    "print(f\"\\nTotal features : {len(feature_columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40224582",
   "metadata": {},
   "source": [
    "### Load labels\n",
    "\n",
    "`human_labels` is used as the ground-truth label column for training and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "f519e9cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (10833, 40)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(metrics_path)\n",
    "label_column = 'human_labels'\n",
    "label = df[label_column].to_list()\n",
    "\n",
    "print(\"Dataset shape:\", df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d71e6f4",
   "metadata": {},
   "source": [
    "## 1) Train across 10 seeds and collect balanced accuracy\n",
    "\n",
    "Each run writes a folder `outputs/cv_seed_<seed>/` containing:\n",
    "- train/test split CSVs (`X_train_data.csv`, `X_test_data.csv`, etc.)\n",
    "- predictions (`y_pred_0.csv`)\n",
    "- the trained pipeline (`best_model.skops`)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b4ae8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Running fold 1/10 with seed 0...\n",
      "Running RandomForestClassifier with imputation median and scaling StandardScaler()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jain\\Anaconda3\\envs\\py311-env\\Lib\\site-packages\\skopt\\space\\space.py:116: UserWarning: Dimension [100, 150] was inferred to Integer(low=100, high=150, prior='uniform', transform='identity'). In upcoming versions of scikit-optimize, it will be inferred to Categorical(categories=(100, 150), prior=None). See the documentation of the check_dimension function for the upcoming API.\n",
      "  warnings.warn(\n",
      "c:\\Users\\jain\\Anaconda3\\envs\\py311-env\\Lib\\site-packages\\skopt\\space\\space.py:116: UserWarning: Dimension [2, 4] was inferred to Integer(low=2, high=4, prior='uniform', transform='identity'). In upcoming versions of scikit-optimize, it will be inferred to Categorical(categories=(2, 4), prior=None). See the documentation of the check_dimension function for the upcoming API.\n",
      "  warnings.warn(\n",
      "c:\\Users\\jain\\Anaconda3\\envs\\py311-env\\Lib\\site-packages\\skopt\\space\\space.py:116: UserWarning: Dimension [2, 4] was inferred to Integer(low=2, high=4, prior='uniform', transform='identity'). In upcoming versions of scikit-optimize, it will be inferred to Categorical(categories=(2, 4), prior=None). See the documentation of the check_dimension function for the upcoming API.\n",
      "  warnings.warn(\n",
      "c:\\Users\\jain\\Anaconda3\\envs\\py311-env\\Lib\\site-packages\\skopt\\space\\space.py:116: UserWarning: Dimension [2, 4] was inferred to Integer(low=2, high=4, prior='uniform', transform='identity'). In upcoming versions of scikit-optimize, it will be inferred to Categorical(categories=(2, 4), prior=None). See the documentation of the check_dimension function for the upcoming API.\n",
      "  warnings.warn(\n",
      "c:\\Users\\jain\\Anaconda3\\envs\\py311-env\\Lib\\site-packages\\skopt\\space\\space.py:116: UserWarning: Dimension [2, 4] was inferred to Integer(low=2, high=4, prior='uniform', transform='identity'). In upcoming versions of scikit-optimize, it will be inferred to Categorical(categories=(2, 4), prior=None). See the documentation of the check_dimension function for the upcoming API.\n",
      "  warnings.warn(\n",
      "c:\\Users\\jain\\Anaconda3\\envs\\py311-env\\Lib\\site-packages\\skopt\\space\\space.py:116: UserWarning: Dimension [100, 150] was inferred to Integer(low=100, high=150, prior='uniform', transform='identity'). In upcoming versions of scikit-optimize, it will be inferred to Categorical(categories=(100, 150), prior=None). See the documentation of the check_dimension function for the upcoming API.\n",
      "  warnings.warn(\n",
      "c:\\Users\\jain\\Anaconda3\\envs\\py311-env\\Lib\\site-packages\\skopt\\space\\space.py:116: UserWarning: Dimension [2, 4] was inferred to Integer(low=2, high=4, prior='uniform', transform='identity'). In upcoming versions of scikit-optimize, it will be inferred to Categorical(categories=(2, 4), prior=None). See the documentation of the check_dimension function for the upcoming API.\n",
      "  warnings.warn(\n",
      "c:\\Users\\jain\\Anaconda3\\envs\\py311-env\\Lib\\site-packages\\skopt\\space\\space.py:116: UserWarning: Dimension [2, 4] was inferred to Integer(low=2, high=4, prior='uniform', transform='identity'). In upcoming versions of scikit-optimize, it will be inferred to Categorical(categories=(2, 4), prior=None). See the documentation of the check_dimension function for the upcoming API.\n",
      "  warnings.warn(\n",
      "c:\\Users\\jain\\Anaconda3\\envs\\py311-env\\Lib\\site-packages\\skopt\\space\\space.py:116: UserWarning: Dimension [100, 150] was inferred to Integer(low=100, high=150, prior='uniform', transform='identity'). In upcoming versions of scikit-optimize, it will be inferred to Categorical(categories=(100, 150), prior=None). See the documentation of the check_dimension function for the upcoming API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Fold 1: Balanced Accuracy = 0.912\n",
      "\n",
      " Running fold 2/10 with seed 1...\n",
      "Running RandomForestClassifier with imputation median and scaling StandardScaler()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jain\\Anaconda3\\envs\\py311-env\\Lib\\site-packages\\skopt\\space\\space.py:116: UserWarning: Dimension [100, 150] was inferred to Integer(low=100, high=150, prior='uniform', transform='identity'). In upcoming versions of scikit-optimize, it will be inferred to Categorical(categories=(100, 150), prior=None). See the documentation of the check_dimension function for the upcoming API.\n",
      "  warnings.warn(\n",
      "c:\\Users\\jain\\Anaconda3\\envs\\py311-env\\Lib\\site-packages\\skopt\\space\\space.py:116: UserWarning: Dimension [2, 4] was inferred to Integer(low=2, high=4, prior='uniform', transform='identity'). In upcoming versions of scikit-optimize, it will be inferred to Categorical(categories=(2, 4), prior=None). See the documentation of the check_dimension function for the upcoming API.\n",
      "  warnings.warn(\n",
      "c:\\Users\\jain\\Anaconda3\\envs\\py311-env\\Lib\\site-packages\\skopt\\space\\space.py:116: UserWarning: Dimension [2, 4] was inferred to Integer(low=2, high=4, prior='uniform', transform='identity'). In upcoming versions of scikit-optimize, it will be inferred to Categorical(categories=(2, 4), prior=None). See the documentation of the check_dimension function for the upcoming API.\n",
      "  warnings.warn(\n",
      "c:\\Users\\jain\\Anaconda3\\envs\\py311-env\\Lib\\site-packages\\skopt\\space\\space.py:116: UserWarning: Dimension [2, 4] was inferred to Integer(low=2, high=4, prior='uniform', transform='identity'). In upcoming versions of scikit-optimize, it will be inferred to Categorical(categories=(2, 4), prior=None). See the documentation of the check_dimension function for the upcoming API.\n",
      "  warnings.warn(\n",
      "c:\\Users\\jain\\Anaconda3\\envs\\py311-env\\Lib\\site-packages\\skopt\\space\\space.py:116: UserWarning: Dimension [2, 4] was inferred to Integer(low=2, high=4, prior='uniform', transform='identity'). In upcoming versions of scikit-optimize, it will be inferred to Categorical(categories=(2, 4), prior=None). See the documentation of the check_dimension function for the upcoming API.\n",
      "  warnings.warn(\n",
      "c:\\Users\\jain\\Anaconda3\\envs\\py311-env\\Lib\\site-packages\\skopt\\space\\space.py:116: UserWarning: Dimension [100, 150] was inferred to Integer(low=100, high=150, prior='uniform', transform='identity'). In upcoming versions of scikit-optimize, it will be inferred to Categorical(categories=(100, 150), prior=None). See the documentation of the check_dimension function for the upcoming API.\n",
      "  warnings.warn(\n",
      "c:\\Users\\jain\\Anaconda3\\envs\\py311-env\\Lib\\site-packages\\skopt\\space\\space.py:116: UserWarning: Dimension [2, 4] was inferred to Integer(low=2, high=4, prior='uniform', transform='identity'). In upcoming versions of scikit-optimize, it will be inferred to Categorical(categories=(2, 4), prior=None). See the documentation of the check_dimension function for the upcoming API.\n",
      "  warnings.warn(\n",
      "c:\\Users\\jain\\Anaconda3\\envs\\py311-env\\Lib\\site-packages\\skopt\\space\\space.py:116: UserWarning: Dimension [2, 4] was inferred to Integer(low=2, high=4, prior='uniform', transform='identity'). In upcoming versions of scikit-optimize, it will be inferred to Categorical(categories=(2, 4), prior=None). See the documentation of the check_dimension function for the upcoming API.\n",
      "  warnings.warn(\n",
      "c:\\Users\\jain\\Anaconda3\\envs\\py311-env\\Lib\\site-packages\\skopt\\space\\space.py:116: UserWarning: Dimension [100, 150] was inferred to Integer(low=100, high=150, prior='uniform', transform='identity'). In upcoming versions of scikit-optimize, it will be inferred to Categorical(categories=(100, 150), prior=None). See the documentation of the check_dimension function for the upcoming API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Fold 2: Balanced Accuracy = 0.905\n",
      "\n",
      " Running fold 3/10 with seed 2...\n",
      "Running RandomForestClassifier with imputation median and scaling StandardScaler()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jain\\Anaconda3\\envs\\py311-env\\Lib\\site-packages\\skopt\\space\\space.py:116: UserWarning: Dimension [100, 150] was inferred to Integer(low=100, high=150, prior='uniform', transform='identity'). In upcoming versions of scikit-optimize, it will be inferred to Categorical(categories=(100, 150), prior=None). See the documentation of the check_dimension function for the upcoming API.\n",
      "  warnings.warn(\n",
      "c:\\Users\\jain\\Anaconda3\\envs\\py311-env\\Lib\\site-packages\\skopt\\space\\space.py:116: UserWarning: Dimension [2, 4] was inferred to Integer(low=2, high=4, prior='uniform', transform='identity'). In upcoming versions of scikit-optimize, it will be inferred to Categorical(categories=(2, 4), prior=None). See the documentation of the check_dimension function for the upcoming API.\n",
      "  warnings.warn(\n",
      "c:\\Users\\jain\\Anaconda3\\envs\\py311-env\\Lib\\site-packages\\skopt\\space\\space.py:116: UserWarning: Dimension [2, 4] was inferred to Integer(low=2, high=4, prior='uniform', transform='identity'). In upcoming versions of scikit-optimize, it will be inferred to Categorical(categories=(2, 4), prior=None). See the documentation of the check_dimension function for the upcoming API.\n",
      "  warnings.warn(\n",
      "c:\\Users\\jain\\Anaconda3\\envs\\py311-env\\Lib\\site-packages\\skopt\\space\\space.py:116: UserWarning: Dimension [2, 4] was inferred to Integer(low=2, high=4, prior='uniform', transform='identity'). In upcoming versions of scikit-optimize, it will be inferred to Categorical(categories=(2, 4), prior=None). See the documentation of the check_dimension function for the upcoming API.\n",
      "  warnings.warn(\n",
      "c:\\Users\\jain\\Anaconda3\\envs\\py311-env\\Lib\\site-packages\\skopt\\space\\space.py:116: UserWarning: Dimension [2, 4] was inferred to Integer(low=2, high=4, prior='uniform', transform='identity'). In upcoming versions of scikit-optimize, it will be inferred to Categorical(categories=(2, 4), prior=None). See the documentation of the check_dimension function for the upcoming API.\n",
      "  warnings.warn(\n",
      "c:\\Users\\jain\\Anaconda3\\envs\\py311-env\\Lib\\site-packages\\skopt\\space\\space.py:116: UserWarning: Dimension [100, 150] was inferred to Integer(low=100, high=150, prior='uniform', transform='identity'). In upcoming versions of scikit-optimize, it will be inferred to Categorical(categories=(100, 150), prior=None). See the documentation of the check_dimension function for the upcoming API.\n",
      "  warnings.warn(\n",
      "c:\\Users\\jain\\Anaconda3\\envs\\py311-env\\Lib\\site-packages\\skopt\\space\\space.py:116: UserWarning: Dimension [2, 4] was inferred to Integer(low=2, high=4, prior='uniform', transform='identity'). In upcoming versions of scikit-optimize, it will be inferred to Categorical(categories=(2, 4), prior=None). See the documentation of the check_dimension function for the upcoming API.\n",
      "  warnings.warn(\n",
      "c:\\Users\\jain\\Anaconda3\\envs\\py311-env\\Lib\\site-packages\\skopt\\space\\space.py:116: UserWarning: Dimension [2, 4] was inferred to Integer(low=2, high=4, prior='uniform', transform='identity'). In upcoming versions of scikit-optimize, it will be inferred to Categorical(categories=(2, 4), prior=None). See the documentation of the check_dimension function for the upcoming API.\n",
      "  warnings.warn(\n",
      "c:\\Users\\jain\\Anaconda3\\envs\\py311-env\\Lib\\site-packages\\skopt\\space\\space.py:116: UserWarning: Dimension [100, 150] was inferred to Integer(low=100, high=150, prior='uniform', transform='identity'). In upcoming versions of scikit-optimize, it will be inferred to Categorical(categories=(100, 150), prior=None). See the documentation of the check_dimension function for the upcoming API.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "all_accuracies = []\n",
    "\n",
    "for seed in range(10):\n",
    "    print(f\"\\n Running fold {seed + 1}/10 with seed {seed}...\")\n",
    "\n",
    "    output_folder = os.path.join(output_base, f\"cv_seed_{seed}\")\n",
    "\n",
    "    trainer = train_model(\n",
    "        mode=\"csv\",\n",
    "        labels=[label],\n",
    "        metrics_paths=[metrics_path],\n",
    "        folder=output_folder,\n",
    "        metric_names=feature_columns,\n",
    "        imputation_strategies=[\"median\"],\n",
    "        scaling_techniques=[\"standard_scaler\"],\n",
    "        classifiers=None,  # Random Forest\n",
    "        test_size=0.2,\n",
    "        seed=seed,\n",
    "        overwrite=True\n",
    "    )\n",
    "\n",
    "    best_model = trainer.best_pipeline\n",
    "\n",
    "    # Load test data and predictions\n",
    "    y_test = pd.read_csv(os.path.join(output_folder, 'y_test_data.csv'))\n",
    "    if 'Unnamed: 0' in y_test.columns:\n",
    "        y_test = y_test.drop('Unnamed: 0', axis=1)\n",
    "    y_test = y_test['0']\n",
    "\n",
    "    y_pred = pd.read_csv(os.path.join(output_folder, 'y_pred_0.csv'))['predicted_labels']\n",
    "\n",
    "    # Balanced accuracy\n",
    "    acc = balanced_accuracy_score(y_test, y_pred)\n",
    "    all_accuracies.append(acc)\n",
    "    print(f\"✔ Fold {seed + 1}: Balanced Accuracy = {acc:.3f}\")\n",
    "\n",
    "# === Plot final results ===\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.boxplot(y=all_accuracies, color='lightgreen')\n",
    "sns.stripplot(y=all_accuracies, color='black', jitter=0.1, size=5)\n",
    "plt.title(\"10 Random Seeds: SUA vs All (Binary Classifier)\")\n",
    "plt.ylabel(\"Balanced Accuracy\")\n",
    "plt.ylim(0.5, 1.0)\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c19b1fa",
   "metadata": {},
   "source": [
    "## 2) SHAP variance across seeds \n",
    "\n",
    "For each seed:\n",
    "- load `best_model.skops`\n",
    "- apply preprocessing (imputer + scaler)\n",
    "- compute SHAP values on the RandomForest step\n",
    "- aggregate `mean(|SHAP|)` per feature\n",
    "\n",
    "We always use **class 1** (SUA) SHAP values to be consistent across different SHAP output formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b107d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n_seeds = 10\n",
    "\n",
    "feature_importances = []\n",
    "accuracies = []\n",
    "best_seed = None\n",
    "best_acc = 0\n",
    "best_explainer = None\n",
    "best_X = None\n",
    "best_shap_values = None\n",
    "\n",
    "for seed in range(n_seeds):\n",
    "    output_folder = os.path.join(output_base, f\"cv_seed_{seed}\")\n",
    "    print(f\"\\n Processing seed {seed}...\")\n",
    "\n",
    "    # Load data\n",
    "    X_test = pd.read_csv(os.path.join(output_folder, 'X_test_data.csv'))\n",
    "    y_test = pd.read_csv(os.path.join(output_folder, 'y_test_data.csv'))\n",
    "    if 'Unnamed: 0' in y_test.columns:\n",
    "        y_test = y_test.drop('Unnamed: 0', axis=1)\n",
    "    y_test = y_test['0']\n",
    "    y_pred = pd.read_csv(os.path.join(output_folder, 'y_pred_0.csv'))['predicted_labels']\n",
    "\n",
    "    # Load trained pipeline using skops\n",
    "    model_path = os.path.join(output_folder, 'best_model.skops')\n",
    "    model = load(model_path, trusted= ['numpy.dtype'])\n",
    "    \n",
    "    # Apply preprocessing\n",
    "    X_input = X_test[feature_columns]\n",
    "    X_input = model.named_steps['imputer'].transform(X_input)\n",
    "    X_input = model.named_steps['scaler'].transform(X_input)\n",
    "\n",
    "    # Compute SHAP for the RF classifier\n",
    "    rf = model.named_steps['classifier']\n",
    "    explainer = shap.TreeExplainer(rf)\n",
    "    shap_vals = explainer.shap_values(X_input)\n",
    "\n",
    "    # ---- NEW robust handling block ----\n",
    "    if isinstance(shap_vals, list):\n",
    "        # Classic multiclass format: list of arrays per class\n",
    "        shap_vals_class_1 = shap_vals[1]  # Class 1 = SUA\n",
    "    elif shap_vals.ndim == 3 and shap_vals.shape[2] == 2:\n",
    "        # SHAP gave a 3D array: (n_samples, n_features, n_classes)\n",
    "        shap_vals_class_1 = shap_vals[:, :, 1]  # select class 1 = SUA\n",
    "    else:\n",
    "        # Already correct shape\n",
    "        shap_vals_class_1 = shap_vals\n",
    "\n",
    "    # Final check\n",
    "    assert shap_vals_class_1.shape[1] == len(feature_columns), \\\n",
    "        f\"SHAP mismatch: got {shap_vals_class_1.shape[1]} features, expected {len(feature_columns)}\"\n",
    "\n",
    "    # Aggregate SHAP values\n",
    "    mean_shap = np.abs(shap_vals_class_1).mean(axis=0)  # shape: (n_features,)\n",
    "    feature_importances.append(pd.Series(mean_shap, index=feature_columns))\n",
    "\n",
    "    # Accuracy\n",
    "    acc = balanced_accuracy_score(y_test, y_pred)\n",
    "    accuracies.append(acc)\n",
    "    print(f\" Seed {seed}: Balanced Accuracy = {acc:.3f}\")\n",
    "\n",
    "    if acc > best_acc:\n",
    "        best_seed = seed\n",
    "        best_acc = acc\n",
    "        best_explainer = explainer\n",
    "        best_X = (X_input, feature_columns)\n",
    "        best_shap_values = shap_vals\n",
    "\n",
    "importance_df = pd.concat(feature_importances, axis=1)\n",
    "importance_df.columns = [f\"Seed_{i}\" for i in range(n_seeds)]\n",
    "\n",
    "mean_importance = importance_df.mean(axis=1)\n",
    "std_importance = importance_df.std(axis=1)\n",
    "\n",
    "sorted_features = mean_importance.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357910bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort all features by mean SHAP value\n",
    "sorted_features = mean_importance.sort_values(ascending=False).index\n",
    "\n",
    "# Bar plot with error bars\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(\n",
    "    x=range(len(sorted_features)),\n",
    "    height=mean_importance[sorted_features],\n",
    "    yerr=std_importance[sorted_features],\n",
    "    capsize=5,\n",
    "    color='lightblue'\n",
    ")\n",
    "plt.xticks(range(len(sorted_features)), sorted_features, rotation=90, ha='right')\n",
    "plt.ylabel(\"Mean(|SHAP value|)\")\n",
    "plt.title(\"SHAP Feature Importance Variance Across 10 Seeds (All Features)\")\n",
    "plt.tight_layout()\n",
    "plt.grid(True, linestyle='--', alpha=0.4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f861d3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b7ecd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(f\"\\n Best model: Seed {best_seed} with accuracy {best_acc:.3f}\")\n",
    "X_input_best, feature_names_best = best_X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34132a9a",
   "metadata": {},
   "source": [
    "## 3) SHAP plots for the best seed\n",
    "\n",
    "We generate:\n",
    "- SHAP summary plot\n",
    "- mean |SHAP| bar plot\n",
    "- decision plot (subsampled to avoid overplotting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6de96b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "best_seed_data = os.path.join(output_base, f\"cv_seed_{best_seed}\")\n",
    "# Load data\n",
    "X_test = pd.read_csv(os.path.join(best_seed_data, 'X_test_data.csv'))\n",
    "y_test =  pd.read_csv(os.path.join(best_seed_data, 'y_test_data.csv'))\n",
    "# Drop 'Unnamed: 0' column if it exists\n",
    "if 'Unnamed: 0' in y_test.columns:\n",
    "    y_test = y_test.drop('Unnamed: 0', axis=1)\n",
    "y_test = y_test['0']\n",
    "\n",
    "y_pred = pd.read_csv(os.path.join(best_seed_data, 'y_pred_0.csv'))\n",
    "\n",
    "# Load model using skops\n",
    "model_path = os.path.join(best_seed_data, 'best_model.skops')\n",
    "best_model_mice_model = load(model_path, trusted= ['numpy.dtype'])\n",
    "\n",
    "# Common function to get SHAP values\n",
    "def preprocess_and_get_shap_values(best_model, X_test, feature_columns):\n",
    "    X_test_transformed = best_model.named_steps['imputer'].transform(X_test[feature_columns])\n",
    "    X_test_final = best_model.named_steps['scaler'].transform(X_test_transformed)\n",
    "    rf = best_model.named_steps['classifier']\n",
    "    samples = X_test_final\n",
    "    explainer = shap.TreeExplainer(rf)\n",
    "    shap_values = explainer.shap_values(samples)\n",
    "    if isinstance(shap_values, list):\n",
    "        shap_values_class1 = shap_values[1]\n",
    "        expected_value = explainer.expected_value[1]\n",
    "    elif len(shap_values.shape) == 3:\n",
    "        shap_values_class1 = shap_values[:, :, 1]\n",
    "        expected_value = explainer.expected_value[1]\n",
    "    else:\n",
    "        shap_values_class1 = shap_values\n",
    "        expected_value = explainer.expected_value\n",
    "    return shap_values_class1, samples, expected_value\n",
    "\n",
    "shap_values_mice, samples_mice, expected_value_mice = preprocess_and_get_shap_values(best_model_mice_model, X_test, feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3897d640",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.title('Summary Plot: best seed model', fontsize=16, fontweight='bold')\n",
    "shap.summary_plot(shap_values_mice, samples_mice, feature_names=feature_columns, show=False)\n",
    "plt.xticks(fontsize=12, fontweight='bold')\n",
    "plt.yticks(fontsize=12, fontweight='bold')\n",
    "plt.show()\n",
    "\n",
    "mean_abs_mice = np.abs(shap_values_mice).mean(axis=0)\n",
    "sorted_idx_mice = np.argsort(-mean_abs_mice)  # sort descending\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.barh(np.array(feature_columns)[sorted_idx_mice], mean_abs_mice[sorted_idx_mice], color='darkorange')\n",
    "plt.title(\"Bar Plot: best seed model\", fontsize=16, fontweight='bold')\n",
    "plt.xlabel(\"Mean |SHAP value|\", fontsize=14, fontweight='bold')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.xticks(fontsize=12, fontweight='bold')\n",
    "plt.yticks(fontsize=10, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "n_samples = 200  \n",
    "\n",
    "# reproducible subsampling\n",
    "rng = np.random.default_rng(seed=42)\n",
    "idx = rng.choice(len(shap_values_mice), size=n_samples, replace=False)\n",
    "\n",
    "# subset SHAP + features\n",
    "shap_subset = shap_values_mice[idx]\n",
    "X_subset = df[feature_columns].iloc[idx]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.title(\"Decision Plot: best seed model (subsampled)\", fontsize=16, fontweight='bold')\n",
    "\n",
    "shap.decision_plot(\n",
    "    expected_value_mice,\n",
    "    shap_subset,\n",
    "    features=X_subset,\n",
    "    feature_names=feature_columns,\n",
    "    show=False\n",
    ")\n",
    "\n",
    "plt.xticks(fontsize=12, fontweight='bold')\n",
    "plt.yticks(fontsize=12, fontweight='bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90fb99e7",
   "metadata": {},
   "source": [
    "## 4) Confusion matrix for the best seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233ff9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, balanced_accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "best_seed_data = os.path.join(output_base, f\"cv_seed_{best_seed}\")\n",
    "# Load data\n",
    "X_test = pd.read_csv(os.path.join(best_seed_data, 'X_test_data.csv'))\n",
    "y_test =  pd.read_csv(os.path.join(best_seed_data, 'y_test_data.csv'))\n",
    "# Drop 'Unnamed: 0' column if it exists\n",
    "if 'Unnamed: 0' in y_test.columns:\n",
    "    y_test = y_test.drop('Unnamed: 0', axis=1)\n",
    "y_test = y_test['0']\n",
    "\n",
    "y_pred = pd.read_csv(os.path.join(best_seed_data, 'y_pred_0.csv'))\n",
    "\n",
    "balanced_acc = balanced_accuracy_score(y_test, y_pred['predicted_labels'])\n",
    "print(f\"Balanced accuracy score: {balanced_acc:.2f}\")\n",
    "\n",
    "# round off the balanced accuracy score to 2 decimal places and convert to percentage\n",
    "balanced_acc_percentage = round(balanced_acc * 100, 2)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred['predicted_labels'])\n",
    "conf_matrix\n",
    "\n",
    "# Calculate percentages\n",
    "total = sum(sum(conf_matrix))\n",
    "conf_matrix_percentages = conf_matrix / total * 100\n",
    "\n",
    "# Define a custom normalization function\n",
    "def custom_norm(data):\n",
    "    max_val = np.max(data)\n",
    "    min_val = np.min(data)\n",
    "    normalized = (data - min_val) / (max_val - min_val)  # Normalize data between 0 and 1\n",
    "    return np.log(normalized * 9 + 1)  # Apply logarithmic transformation for contrast\n",
    "\n",
    "# Normalize the confusion matrix data\n",
    "normalized_matrix = custom_norm(conf_matrix_percentages)\n",
    "\n",
    "# Increase figure size to provide more space\n",
    "plt.figure(figsize=(8, 8))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix_percentages, display_labels=[0, 1])\n",
    "\n",
    "# Plot confusion matrix with percentages\n",
    "plt.imshow(normalized_matrix, interpolation='nearest', cmap='Greens')\n",
    "\n",
    "# Display percentages in each cell with bold text\n",
    "for i in range(conf_matrix.shape[0]):\n",
    "    for j in range(conf_matrix.shape[1]):\n",
    "        # Define color based on whether it's the diagonal or off-diagonal element\n",
    "        color = 'black' if i == j else 'black'  # Swap 'white' and 'black'\n",
    "        plt.text(j, i, f\"{conf_matrix_percentages[i, j]:.2f}%\", ha='center', va='center', fontsize=40, color=color, weight='bold')\n",
    "\n",
    "# Customizing x and y tick labels and increasing font size\n",
    "plt.xticks(range(len(disp.display_labels)), ['MUA-Noise','SUA'], fontsize=28)\n",
    "plt.yticks(range(len(disp.display_labels)), [ 'MUA-Noise','SUA',], rotation=90, fontsize=28, verticalalignment='center')  # Rotate y-axis ticks\n",
    "\n",
    "# Add description below the confusion matrix\n",
    "description = f\"balanced accuracy of {balanced_acc_percentage}%\"\n",
    "\n",
    "plt.title(description, wrap=True, horizontalalignment='center', fontsize=30, weight='bold')\n",
    "\n",
    "# Increase font size for title and labels\n",
    "plt.xlabel('Predicted Label', fontsize=28)\n",
    "plt.ylabel('Human Label', fontsize=28)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c40cf8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6754f116",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
